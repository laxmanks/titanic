{"cells":[{"metadata":{"_uuid":"363cc0d2-544b-4e2b-9823-84b1f309b7ac","_cell_guid":"6abceea9-80d7-4077-92f3-2d979aa953eb","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trd = pd.read_csv(\"/kaggle/input/titanic/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ted = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in [trd,ted] :\n    mean = trd.Age.mean()\n    std =  ted.Age.std()\n    is_null= data.Age.isnull().sum()\n    randintegers =np.random.randint(mean-std,mean+std,is_null)\n    temp_age=data[\"Age\"].copy()\n    temp_age[data.Age.isnull()]=randintegers\n    data[\"Age\"]=temp_age\ntod = trd.copy()\ntod = tod.append(ted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tod.loc[tod.Embarked.isnull(),'Embarked'] ='S'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tod.Fare = tod.Fare.fillna(0)\ntod.Fare = tod.Fare.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsex_dummies=pd.get_dummies(tod[\"Sex\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Embarked_dummies=pd.get_dummies(tod['Embarked'])\ntod=tod.drop(columns=['PassengerId','Sex','Embarked','Ticket'])\ntod\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [tod]\n#titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\nfor dataset in data:\n    # extract titles\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    # replace titles with a more common title or as Rare\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    # convert titles into numbers\n    #dataset['Title'] = dataset['Title'].map(titles)\n    # filling NaN with 0, to get safe\n    #dataset['Title'] = dataset['Title'].fillna(0)\n\ntitle_dummies=pd.get_dummies(tod.Title)\ntitle_dummies\ncabin_holder=tod['Cabin']\ncabin_holder\ntod = tod.drop(['Name','Cabin','Title'], axis=1)\ntod =pd.concat([tod,sex_dummies,title_dummies,Embarked_dummies],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=tod.iloc[0:891,:]\nY_train=X_train[\"Survived\"]\nX_train=X_train.drop(columns='Survived')\nX_test=tod.iloc[891:,:]\nX_test=X_test.drop(columns='Survived')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.linear_model import LogisticRegression\n#logreg = LogisticRegression()\n#logreg.fit(X_train, Y_train)\n\n#Y_pred = logreg.predict(X_test)\n\n#acc_log = round(logreg.score(X_train, Y_train) * 100, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_prediction = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nY_prediction=pd.Series(Y_prediction)\nY_prediction=pd.concat([ted['PassengerId'],Y_prediction],axis=1)\nY_prediction.to_csv('mcsvfile.csv',index=False)\nY_prediction","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}